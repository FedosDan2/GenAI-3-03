import streamlit as st
import sys
import random
from transformers import pipeline
from langdetect import detect, DetectorFactory

sys.path.append('/home/fedosdan2/prog/pr_act/GenAI-3-03/GenAi-1-05-chat_bot')
sys.path.append('/home/fedosdan2/prog/pr_act/GenAI-3-03/third_course_ML/code/Block1/GenAI-1-06')
import pac1
import task 

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
PREDEFINED_RESPONSES_RU = [
    "–ú–Ω–µ –æ—á–µ–Ω—å –∂–∞–ª—å, —á—Ç–æ –≤—ã —Ç–∞–∫ —Å–µ–±—è —á—É–≤—Å—Ç–≤—É–µ—Ç–µ. –î–∞–≤–∞–π—Ç–µ –ø–æ–≥–æ–≤–æ—Ä–∏–º –æ —á—ë–º-–Ω–∏–±—É–¥—å —Ö–æ—Ä–æ—à–µ–º! –ù–∞–ø—Ä–∏–º–µ—Ä, —á—Ç–æ –≤–∞—Å —Ä–∞–¥–æ–≤–∞–ª–æ –Ω–∞ —ç—Ç–æ–π –Ω–µ–¥–µ–ª–µ?",
    "–°–ø–∞—Å–∏–±–æ, —á—Ç–æ –ø–æ–¥–µ–ª–∏–ª–∏—Å—å. –ò–Ω–æ–≥–¥–∞ –ø–æ–º–æ–≥–∞–µ—Ç —Å–º–µ–Ω–∏—Ç—å —Ñ–æ–∫—É—Å ‚Äî –∞ –≤—ã –ª—é–±–∏—Ç–µ —Å–º–æ—Ç—Ä–µ—Ç—å –∑–∞–∫–∞—Ç—ã –∏–ª–∏ —Ä–∞—Å—Å–≤–µ—Ç—ã?",
    "–Ø –≤–∞—Å —Å–ª—ã—à—É. –ê –∑–Ω–∞–µ—Ç–µ, —á—Ç–æ —Å–µ–≥–æ–¥–Ω—è –≤ –º–∏—Ä–µ –ø—Ä–æ–∏–∑–æ—à–ª–æ —á—Ç–æ-—Ç–æ –¥–æ–±—Ä–æ–µ? –•–æ—Ç–∏—Ç–µ, —Ä–∞—Å—Å–∫–∞–∂—É?",
    "–í—Å—ë –≤—Ä–µ–º–µ–Ω–Ω–æ ‚Äî –∏ –ø–ª–æ—Ö–æ–µ, –∏ —Ö–æ—Ä–æ—à–µ–µ. –ê –≤—ã –≤–µ—Ä–∏—Ç–µ, —á—Ç–æ –∑–∞–≤—Ç—Ä–∞ –±—É–¥–µ—Ç –ª—É—á—à–µ?",
    "–ò–Ω–æ–≥–¥–∞ –≤—Å—ë –∫–∞–∂–µ—Ç—Å—è —Å–µ—Ä—ã–º, –Ω–æ —è –≤–µ—Ä—é, —á—Ç–æ –≤–ø–µ—Ä–µ–¥–∏ —Å–≤–µ—Ç–ª–æ–µ! –•–æ—Ç–∏—Ç–µ –æ–±—Å—É–¥–∏—Ç—å —á—Ç–æ-—Ç–æ –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–µ–µ?"
]

PREDEFINED_RESPONSES_EN = [
    "I'm really sorry you're feeling this way. Let's talk about something good! For example, what made you happy this week?",
    "Thank you for sharing. Sometimes it helps to shift focus ‚Äî do you enjoy watching sunsets or sunrises?",
    "I hear you. Did you know something kind happened in the world today? Would you like me to tell you about it?",
    "Everything is temporary ‚Äî both the bad and the good. Do you believe tomorrow will be better?",
    "Sometimes everything seems gray, but I believe brighter days are ahead! Would you like to discuss something inspiring?"
]

MODEL_NAME = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

CLASSIFIER_NAME = "nlptown/bert-base-multilingual-uncased-sentiment"

MAX_LEN = 512


@st.cache_resource
def load_translation_pipelines():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ä—É—Å—Å–∫–∏–º –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–º —è–∑—ã–∫–∞–º–∏.

    Returns:
        tuple: –ö–æ—Ä—Ç–µ–∂ –∏–∑ –¥–≤—É—Ö –æ–±—ä–µ–∫—Ç–æ–≤ pipeline:
            - en2ru (pipeline): –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π.
            - ru2en (pipeline): –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–æ–¥–∞ —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π.
            –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (None, None).
    """

    try:
        en2ru = pipeline("translation_en_to_ru", model="Helsinki-NLP/opus-mt-en-ru", device=-1)
        ru2en = pipeline("translation_ru_to_en", model="Helsinki-NLP/opus-mt-ru-en", device=-1)
        return en2ru, ru2en
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π –ø–µ—Ä–µ–≤–æ–¥–∞: {e}")
        return None, None


def safe_detect_language(text: str) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∏—Å–∫–ª—é—á–µ–Ω–∏–π.

    Args:
        text (str): –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.

    Returns:
        str: –ö–æ–¥ —è–∑—ã–∫–∞ ('en' –∏–ª–∏ 'ru'). –ü—Ä–∏ –æ—à–∏–±–∫–µ –∏–ª–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–º —è–∑—ã–∫–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 'en'.
    """

    try:
        lang = detect(text)
        return lang if lang in ["en", "ru"] else "en"
    except:
        return "en"


def safe_translate(text: str, translator, src_lang: str, tgt_lang: str) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –ø–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –¥–ª–∏–Ω—ã.

    Args:
        text (str): –¢–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞.
        translator (pipeline): –û–±—ä–µ–∫—Ç –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏–∑ transformers.
        src_lang (str): –ö–æ–¥ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —è–∑—ã–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'en').
        tgt_lang (str): –ö–æ–¥ —Ü–µ–ª–µ–≤–æ–≥–æ —è–∑—ã–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'ru').

    Returns:
        str: –ü–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç. –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç.
    """

    try:
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Ç–µ–∫—Å—Ç–∞ (–º–æ–¥–µ–ª—å –Ω–µ –ª—é–±–∏—Ç –¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏)
        max_len = MAX_LEN
        if len(text) > max_len:
            text = text[:max_len]
        result = translator(text)
        return result[0]['translation_text']
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ ({src_lang}‚Üí{tgt_lang}): {str(e)[:100]}")
        return text  # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª


@st.cache_resource
def load_chatbot():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å —á–∞—Ç-–±–æ—Ç–∞ –∏ –µ—ë —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä.

    Returns:
        tuple: –ö–æ—Ä—Ç–µ–∂ (chatbot, tokenizer) –∏–ª–∏ (None, None) –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏.
    """

    chatbot, tokenizer = pac1.create_chatbot(model_name=MODEL_NAME, device=-1)
    if chatbot is None:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å —á–∞—Ç–∞.")
        return None, None
    return chatbot, tokenizer


@st.cache_resource
def load_classifier():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç –º–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.

    Returns:
        pipeline or None: –û–±—ä–µ–∫—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏.
    """

    classifier = task.load_classifier(CLASSIFIER_NAME)
    if classifier is None:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.")
        return None
    return classifier


def generate_topic_shift_reply(chatbot, tokenizer, history, user_input):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –º—è–≥–∫–æ –º–µ–Ω—è–µ—Ç —Ç–µ–º—É –ø—Ä–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.

    Args:
        chatbot (pipeline): –ú–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.
        tokenizer (AutoTokenizer): –¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏.
        history (list[dict]): –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{"role": "...", "content": "..."}, ...].
        user_input (str): –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Returns:
        str: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –±–æ—Ç–∞ –±–µ–∑ –ø—Ä–æ–º–ø—Ç–∞ –∏ —Å—Ç–æ–ø-—Ç–æ–∫–µ–Ω–æ–≤.
    """

    messages = history + [
        {"role": "user", "content": user_input},
        {"role": "system", "content": "The user seems upset. Respond kindly and gently change the topic to something positive or neutral."}
    ]
    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    result = chatbot(
        prompt,
        max_new_tokens=MAX_LEN,
        do_sample=True,
        top_k=50,
        top_p=0.95,
        pad_token_id=tokenizer.eos_token_id
    )
    generated = result[0]["generated_text"]
    reply = generated[len(prompt):]
    for stop in ["<|user|>", "<|system|>", "<|assistant|>", "</s>"]:
        if stop in reply:
            reply = reply.split(stop)[0]
            break
    return reply.strip()


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ Streamlit-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —á–∞—Ç-–±–æ—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –¥–≤—É—Ö —è–∑—ã–∫–æ–≤.

    –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:
    - –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫ –≤–≤–æ–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (—Ä—É—Å—Å–∫–∏–π/–∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
    - –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è
    - –ü—Ä–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–π —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —Å–º–µ–Ω–∏—Ç—å —Ç–µ–º—É
    - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ä–µ–∂–∏–º–∞ –æ—Ç–≤–µ—Ç–∞: –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –∑–∞–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –æ—Ç–≤–µ—Ç—ã –Ω–∞ —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """

    st.set_page_config(page_title="Ask GigaChat", page_icon="üí¨", layout="centered")
    st.title("üí¨ Ask GigaChat")
    st.markdown("–î—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä—É—Å—Å–∫–æ–≥–æ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤")

    use_dynamic = st.toggle("–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è", value=True)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï –º–æ–¥–µ–ª–∏
    chatbot, tokenizer = load_chatbot()
    classifier = load_classifier()
    en2ru, ru2en = load_translation_pipelines()
    
    if None in [chatbot, classifier, en2ru, ru2en]:
        st.stop()

    if "history" not in st.session_state:
        st.session_state.history = []

    for message in st.session_state.history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    prompt = st.chat_input("–ù–∞–ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
    if prompt:
        with st.chat_message("user"):
            st.markdown(prompt)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_lang = safe_detect_language(prompt)
        st.caption(f"–Ø–∑—ã–∫: {user_lang}")

        # –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º, –ø–æ—ç—Ç–æ–º—É –ø–µ—Ä–µ–≤–æ–¥–∏–º –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
        analysis_text = prompt
        if user_lang == "ru":
            analysis_text = safe_translate(prompt, ru2en, "ru", "en")
        
        sentiment, score = task.analyze_sentiment(analysis_text, classifier)
        st.caption(f"–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {sentiment} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {score:.2f})")

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("–î—É–º–∞—é... ü§î")

            if sentiment == "negative":
                if use_dynamic:
                    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –ê–ù–ì–õ–ò–ô–°–ö–û–ú (–º–æ–¥–µ–ª—å TinyLlama ‚Äî –∞–Ω–≥–ª–∏–π—Å–∫–∞—è)
                    bot_reply_en = generate_topic_shift_reply(chatbot, tokenizer, st.session_state.history, analysis_text)
                    # –ü–µ—Ä–µ–≤–æ–¥–∏–º –Ω–∞ —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    bot_reply = safe_translate(bot_reply_en, en2ru, "en", "ru") if user_lang == "ru" else bot_reply_en
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—É—é —Ñ—Ä–∞–∑—É –Ω–∞ –Ω—É–∂–Ω–æ–º —è–∑—ã–∫–µ
                    bot_reply = random.choice(PREDEFINED_RESPONSES_RU if user_lang == "ru" else PREDEFINED_RESPONSES_EN)
            else:
                # –û–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç
                bot_reply_en = pac1.get_bot_reply(chatbot, tokenizer, st.session_state.history, analysis_text)
                bot_reply = safe_translate(bot_reply_en, en2ru, "en", "ru") if user_lang == "ru" else bot_reply_en

            message_placeholder.markdown(bot_reply)

        st.session_state.history.append({"role": "user", "content": prompt})
        st.session_state.history.append({"role": "assistant", "content": bot_reply})


if __name__ == "__main__":
    main()